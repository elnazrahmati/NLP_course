{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5202e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9280492",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "خواندن فایل و تبدیل به  متغیهای iran_geog_keywords، keyword و texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3dc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file\n",
    "keyword = open('sport_key_words.txt', 'r', encoding = 'utf-8').readlines()\n",
    "texts = open('source.txt', 'r', encoding = 'utf-8').readlines()\n",
    "geog_keywords = open('countries_cities.csv', 'r', encoding = 'utf-8').readlines()\n",
    "iran_geog_keywords = open('city_iran.csv', 'r', encoding = 'utf-8').readlines()\n",
    "\n",
    "max_allowded_space = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f779168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    texts = []\n",
    "    for word in file:\n",
    "        text = word.rstrip('\\n')\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "key = read_file(keyword)\n",
    "text = read_file(texts)\n",
    "geog_keyword = read_file(geog_keywords+iran_geog_keywords) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cc736",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "مجموعه ای از کلمات کلیدی در مورد 'ورزش' داریم.\n",
    "\n",
    "اگر الگویی از این کلمات را بتوان در جمله ی ورودی یافت، در این صورت سراغ زیر گروه های می رویم (که روش آن را در تابع بیشتر توضیح خواهیم داد). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "4bc8c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_key_word = ''.join([i+'|' for i in key if len(i)>2])\n",
    "\n",
    "types = ['برد و باخت و تساوی'  , 'صعود و سقوط و حذف' ,  'قهرمان و نایب قهرمان' , 'کسب مدال']\n",
    "\n",
    "sub_key_1 = 'برد|باخت|تساوی' # type = 'برد و باخت و تساوی'\n",
    "sub_key_2 = 'صعود|سقوط|حذف' # type = 'صعود و سقوط و حذف'\n",
    "sub_key_3 = 'قهرمان|نایب قهرمان' # type = 'قهرمان و نایب قهرمان'\n",
    "sub_key_4 = 'مدال' # type = 'کسب مدال'\n",
    "\n",
    "key_verbs = r'است|کرد|شد|بود'\n",
    "\n",
    "geog_key_word = ''.join([i.strip() +'|' for i in re.sub('\\\"|\\'|\\]|\\[|u200c','',str(geog_keyword).lower().replace('\\\\',' ').replace('  ',' ')).split(',') if len(i)>2 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df115fc",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "در این قسمت می خواهیم مکان را پیدا کنیم.\n",
    "\n",
    "برای پیدا کردن مکان ما دو مشکل برخورد کردیم:\n",
    "\n",
    "۱ - که برخی از مکان ها توسط parsi_io پیدا نمی شدند. برای این کار یک دیتاست کوچک از شهر های معروف شهر های کشور های جهان و ایران جمع کردیم. روش کار به این صورت است:\n",
    "\n",
    "$~~~~~~$ ۱ - از parsi_io استفاده می کنیم، اگر مکانی پیدا نکرد به دیتاست رجوع می کنیم\n",
    "\n",
    "$~~~~~~$ ۲ - به دیتاست جانبی مراجعه می کنیم و اگر مکان را یافت، از آن استفاده می کنیم.\n",
    "\n",
    "$~~~~~~$ ۳ - در غیر این صورت، مقدار تهی را جایگذاری می کنیم.\n",
    "\n",
    "\n",
    "۲ - در برخی از جملات بیش از یک کلمه به عنوان مکان معرفی می شد. در برخی از مواقع، تنها نام یک مکان برده شده اما مکان وقوع نیست برای این کار ما برای بهبود از وجود کلمه ی \"در\" داخل جمله استفاده کردیم که مراحل به صورت زیر است:\n",
    "\n",
    "$~~~~~~$ ۱ - اگر تنها یک مکان داریم، کاری انجام نمی دهیم.\n",
    "\n",
    "$~~~~~~$ ۲ - اگر بیش از یک کلمه به عنوان مکان انتخاب شده بود، کلمه ی \"در\" را در متن جستجو می کنیم و مکان شروع آن، جایگاه کلمه در جمله را بیان می کند.\n",
    "\n",
    "برای مثال: جمله ی 'در جام جهانی والیبال در قزاقستان تیم ایران موفق به کسب مدال نقره شد.'\n",
    " مکان های پیدا شده: \n",
    " \n",
    " ['قزاقستان', 'ایران'] \n",
    " [24, 32, 37, 42]\n",
    " \n",
    " مکان \"در\" در جمله:\n",
    " [0, 2, 21, 23] \n",
    " دو \"در\" در جمله وجود دارد.\n",
    "         \n",
    "$~~~~~~$ ۳ - اکنون برای هر \"در\" مشاهده شده در جمله، \"جایگاه نقطه ی شروع مکان های پیدا شده، نسبت به کلمه ی 'در'\" را پیدا می کنیم، به عبارت دیگر، مکان های پیدا شده توسط ما، چقدر با کلمه ی 'در' فاصله دارد؟ برای این کار از تفاضل نقطه ی شروع مکان ها و مکان 'در' استفاده می کنیم.(برای هر باری که 'در' داخل جمله وجود دارد، این کار را تکرار می کنیم) بدیهی است که اگر این مقدار منفی باشد، باید از آن صرفه نظر کرد('در تهران' مقدارش مثبت شده و این 'در' اشاره به مکان بودن 'تهران دارد' و 'تهران در' مقدارش منفی که یعنی این 'در' درکنار 'تهران' جهت نمایش مکان بودن نیامده، شاید 'در'های دیگر موجود در جمله، به مکان بودن 'تهران اشاره کند' ) در نهایت کلمه ای که کمترین فاصله تا 'در' را دارد و این فاصله کمتر از مقداری معین است(۱ + تعداد space های مجاز بین انتهای 'در' و شروع کلمه ی بعدی)، به عنوان مکان انتخاب می شود.  برای صرفه نظر کردن، مقدار طول جمله را آن نسبت می دهیم که در argmin هرگز انتخاب نشود. \n",
    "\n",
    "ادامه ی مثال:\n",
    "\n",
    "برای 'در' اول:\n",
    "[24 37]\n",
    "این یعنی همه مکان ها بعد از این 'در' آمده اند و از طرفی فاصله ی آن با کلمات معرف مکان زیاد است. پس از این 'در' اطلاعات خاصی نتوانستیم بدست آوریم.منظورمان مکان 'ایران' است.\n",
    "\n",
    "برای 'در' دوم:\n",
    "[3 16]\n",
    "این یعنی همه مکان ها بعد از این 'در' آمده اند و از طرفی فاصله ی آن با یکی از کلمات معرف مکان کم است. پس از آن کلمه ی مکانی، مکان وقوع است. که این مکان 'قزاقستان' است.\n",
    "\n",
    "$~~~~~~$ ۴ - اگر فاصله ی تمام کلمات از 'در' بیشتر از حد مجاز بود یا به هر دلیلی از این روش نتوانستیم مکانی، یا مکان هایی را تشخیص بدهیم(جمله ی 'در شیراز، در تبریز' دو 'در' و هر کدام یک مکان دارند که قابل تشخیص است)، همان خروجی مرحله ی قبل را برمی‌گرداند. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96ca94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find locations\n",
    "\n",
    "from parsi_io.modules.address_extractions import AddressExtraction\n",
    "\n",
    "def location_extraction(line):\n",
    "    \n",
    "    extractor = AddressExtraction()\n",
    "\n",
    "    loc = {'address':[],'address_span':[]}\n",
    "\n",
    "    # 'address' 'address_span'\n",
    "    ex_result = extractor.run(line)\n",
    "\n",
    "    if len(ex_result['address'])>0 :\n",
    "        loc['address'] = ex_result['address']\n",
    "        loc['address_span'] = ex_result['address_span']\n",
    "    else:\n",
    "        re_results = re.finditer(geog_key_word,line)\n",
    "        for re_result in re_results:\n",
    "            detected_loc = line[re_result.span()[0]:re_result.span()[1]]\n",
    "            if len(detected_loc)>1:\n",
    "                loc['address'].append(line[re_result.span()[0]:re_result.span()[1]])\n",
    "                loc['address_span'] += [re_result.span()[0],re_result.span()[1]]\n",
    "        \n",
    "    # if more than 1 loc\n",
    "    if len(loc['address'])>1:\n",
    "        dar_in_loc = 'در'\n",
    "        dar_span = []\n",
    "        re_dar_results = re.finditer(dar_in_loc,line)\n",
    "        for re_dar_result in re_dar_results:\n",
    "            detected_dar = line[re_dar_result.span()[0]:re_dar_result.span()[1]]\n",
    "            if len(detected_dar)>1:\n",
    "                dar_span += [re_dar_result.span()[0],re_dar_result.span()[1]]\n",
    "                \n",
    "        real_locs = []\n",
    "        real_locs_span = []\n",
    "        for span in dar_span[::2]:\n",
    "            temp = (np.array(loc['address_span'][::2])  - span)\n",
    "            temp[temp<0] = len(line)\n",
    "            \n",
    "            if np.min(temp)!= len(line) and np.min(temp)< max_allowded_space :\n",
    "    \n",
    "                real_loc = np.argmin(temp)\n",
    "                real_locs.append(loc['address'][real_loc])\n",
    "                real_locs_span +=[loc['address_span'][2*real_loc],loc['address_span'][2*real_loc+1]]\n",
    "        if len(real_locs)>0:        \n",
    "            return dict({'address':real_locs,'address_span':real_locs_span})\n",
    "    \n",
    "    \n",
    "    if len(loc['address']) == 0:\n",
    "        loc['address'] = ['']\n",
    "        loc['address_span'] = ['']\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfa569",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "برای پبدا کردن کلمات کلیدی، همان روش معمولی استفاده از RegEx را بکار گرفتیم. تا در وحله ی اول ببینیم آیا موضوع ورزشی هست یا خیر؟ سپس بازه ی وجود کلمات کلیدی را هم بیابیم.\n",
    "برای پیدا کردن عبارت کلیدی، بازی 'شروع اولین کلمه ی کلیدی' تا 'انتهای آخرین کلمه ی کلیدی' را به عنوان مکان عبارت کلیدی در نظر گرفتیم.\n",
    "\n",
    "نکته ای وجود دارد و آن هم این است که گاهی text به صورت \"کسب مدال طلا\" می آید و گاهی یک جمله به طور کامل \"بازیکن هلندی تبار عنوان نایب قهرمان را کسب کرد\" و افعال جزو عبارات کلیدی نیستند. برای این مسئله، RegEx ای از افعال پر کاربرد ساختیم و اگر فاصله ی 'شروع فعل'  تا 'انتهای عبارت کلیدی' از حدی کمتر بود، 'انتهای عبارت کلیدی' را به 'انتهای فعل' گسترش دادیم.\n",
    "\n",
    "در نهایت بر اساس این که کلمات کدام زیر شاخه از شاخه ی اصلی بیشتر در عبارت پیدا شده، زیر شاخه ی آن را تعیین می کنیم.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5ec95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_text_extraction(line):\n",
    "    \n",
    "    line_key_start_span_list = []\n",
    "    line_key_end_span_list = []\n",
    "    line_keys = []\n",
    "\n",
    "    keys = re.finditer(sport_key_word,line)\n",
    "    \n",
    "    is_it_about_sport = False\n",
    "    for k in keys: \n",
    "\n",
    "        if (k.span()[1] - k.span()[0])>1: \n",
    "            is_it_about_sport = True\n",
    "            \n",
    "            line_keys.append(line[k.span()[0]:k.span()[1]])\n",
    "            line_key_start_span_list += [k.span()[0]]\n",
    "            line_key_end_span_list += [k.span()[1]]\n",
    "    if not is_it_about_sport:\n",
    "        return 0\n",
    "    \n",
    "    line_key_start_span = line_key_start_span_list[ np.argmin(line_key_start_span_list) ]\n",
    "    line_key_end_span = line_key_end_span_list[ np.argmax(line_key_end_span_list) ]\n",
    "\n",
    "\n",
    "\n",
    "    line_verbs_span = []\n",
    "    verbs = re.finditer(key_verbs,line)\n",
    "\n",
    "    for v in verbs:\n",
    "        line_verbs_span = line[v.span()[0]:v.span()[1]]\n",
    "\n",
    "        if (v.span()[1]-v.span()[0])>1:\n",
    "\n",
    "            if v.span()[0] - line_key_end_span < 3*max_allowded_space: # 3 words\n",
    "                line_key_end_span = v.span()[1]\n",
    "\n",
    "    # detecting the type\n",
    "    \n",
    "    result_types = []\n",
    "\n",
    "    result_types.append(len([i for i in re.finditer(sub_key_1,line) if (i.span()[1] - i.span()[0])>1]))\n",
    "    result_types.append(len([i for i in re.finditer(sub_key_2,line) if (i.span()[1] - i.span()[0])>1]))\n",
    "    result_types.append(len([i for i in re.finditer(sub_key_3,line) if (i.span()[1] - i.span()[0])>1]))\n",
    "    result_types.append(len([i for i in re.finditer(sub_key_4,line) if (i.span()[1] - i.span()[0])>1]))\n",
    "\n",
    "    return dict({'text':line[line_key_start_span : line_key_end_span] ,\n",
    "                 'span':[line_key_start_span,line_key_end_span] ,\n",
    "                 'type':types[np.argmax(result_types)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "64074782",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for line in text:\n",
    "    \n",
    "    result = dict({\"line\":line ,\"type\":'' ,\"text\":'' ,\"span\":None ,\"place\":'',\"time\":'' })\n",
    "    \n",
    "    # detecting locations\n",
    "    \n",
    "    loc = location_extraction(line)\n",
    "    result['place'] = loc['address']\n",
    "    \n",
    "    # detecting key words\n",
    "    \n",
    "    type_text = type_text_extraction(line)\n",
    "    result['type'] = type_text['type']\n",
    "    result['span'] = type_text['span']\n",
    "    result['text'] = type_text['text']\n",
    "    results.append(result)\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "169eae94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'line': 'در دیدار شب گذشته در مادرید تیم اتلتیکو مادرید به مرحله مسابقات صعود کرد.',\n",
       "  'type': 'صعود و سقوط و حذف',\n",
       "  'text': 'تیم اتلتیکو مادرید به مرحله مسابقات صعود کرد',\n",
       "  'span': [28, 72],\n",
       "  'place': ['مادرید'],\n",
       "  'time': ''},\n",
       " {'line': 'بازیکن هلندی تبار عنوان نایب قهرمان را کسب کرد.',\n",
       "  'type': 'قهرمان و نایب قهرمان',\n",
       "  'text': 'بازیکن هلندی تبار عنوان نایب قهرمان را کسب کرد',\n",
       "  'span': [0, 46],\n",
       "  'place': [],\n",
       "  'time': ''},\n",
       " {'line': 'در جام جهانی والیبال در قزاقستان تیم ایران موفق به کسب مدال نقره شد.',\n",
       "  'type': 'کسب مدال',\n",
       "  'text': 'جام جهانی والیبال در قزاقستان تیم ایران موفق به کسب مدال نقره شد',\n",
       "  'span': [3, 67],\n",
       "  'place': ['قزاقستان'],\n",
       "  'time': ''}]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129160a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
