{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4qpa-r3M8d8",
        "outputId": "37d1f10b-4faa-47b7-e427-986b14d58a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-03 07:43:42--  https://tanzil.net/trans/en.ahmedali\n",
            "Resolving tanzil.net (tanzil.net)... 209.95.51.187, 136.243.149.84\n",
            "Connecting to tanzil.net (tanzil.net)|209.95.51.187|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘en.ahmedali’\n",
            "\n",
            "en.ahmedali             [ <=>                ] 806.33K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-06-03 07:43:42 (8.33 MB/s) - ‘en.ahmedali’ saved [825681]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://tanzil.net/trans/en.ahmedali"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('en.ahmedali') as f:\n",
        "    lines = f.readlines()"
      ],
      "metadata": {
        "id": "omIwXe-2lDBq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "sura, aya, text = [], [], []\n",
        "for line in lines:\n",
        "    temp = line.split('|')\n",
        "    if len(temp)==3:\n",
        "      sura.append(int(temp[0]))\n",
        "      aya.append(int(temp[1]))\n",
        "      text.append(temp[2])\n",
        "df = pd.DataFrame()\n",
        "df['sura'] = sura\n",
        "df['aya'] = aya\n",
        "df['text'] = text\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_AQ2QX2ul5DG",
        "outputId": "a4be9453-0d34-4b2a-dcc7-942806c3bec9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      sura  aya                                               text\n",
              "0        1    1  In the name of Allah, most benevolent, ever-me...\n",
              "1        1    2  ALL PRAISE BE to Allah, Lord of all the worlds,\\n\n",
              "2        1    3                  Most beneficent, ever-merciful,\\n\n",
              "3        1    4                    King of the Day of Judgement.\\n\n",
              "4        1    5  You alone we worship, and to You alone turn fo...\n",
              "...    ...  ...                                                ...\n",
              "6231   114    2                                 The King of men,\\n\n",
              "6232   114    3                                  The God of men,\\n\n",
              "6233   114    4  From the evil of him who breathes temptations ...\n",
              "6234   114    5  Who suggests evil thoughts to the hearts of me...\n",
              "6235   114    6                    From among the jinns and men.\\n\n",
              "\n",
              "[6236 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f70c32fe-2445-4c67-9443-5fdeeb6f6137\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sura</th>\n",
              "      <th>aya</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>In the name of Allah, most benevolent, ever-me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>ALL PRAISE BE to Allah, Lord of all the worlds,\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Most beneficent, ever-merciful,\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>King of the Day of Judgement.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>You alone we worship, and to You alone turn fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6231</th>\n",
              "      <td>114</td>\n",
              "      <td>2</td>\n",
              "      <td>The King of men,\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6232</th>\n",
              "      <td>114</td>\n",
              "      <td>3</td>\n",
              "      <td>The God of men,\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6233</th>\n",
              "      <td>114</td>\n",
              "      <td>4</td>\n",
              "      <td>From the evil of him who breathes temptations ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6234</th>\n",
              "      <td>114</td>\n",
              "      <td>5</td>\n",
              "      <td>Who suggests evil thoughts to the hearts of me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6235</th>\n",
              "      <td>114</td>\n",
              "      <td>6</td>\n",
              "      <td>From among the jinns and men.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6236 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f70c32fe-2445-4c67-9443-5fdeeb6f6137')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f70c32fe-2445-4c67-9443-5fdeeb6f6137 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f70c32fe-2445-4c67-9443-5fdeeb6f6137');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2QNUCo3lOJ4b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OEyFKIbJOKPB"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "\n",
        "    # Replace punctuation with tokens so we can use them in our model\n",
        "    text = text.lower()\n",
        "    text = text.replace('.', ' <PERIOD> ')\n",
        "    text = text.replace(',', ' <COMMA> ')\n",
        "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
        "    text = text.replace(';', ' <SEMICOLON> ')\n",
        "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
        "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    text = text.replace('(', ' <LEFT_PAREN> ')\n",
        "    text = text.replace(')', ' <RIGHT_PAREN> ')\n",
        "    text = text.replace('--', ' <HYPHENS> ')\n",
        "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    text = text.replace('\\n', '')\n",
        "    text = text.replace(':', ' <COLON> ')\n",
        "    words = text.split()\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAtN_S3-Vfw2",
        "outputId": "1103377b-8a6e-4da5-a039-8a7aa6b663d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in', 'the', 'name', 'of', 'allah', '<COMMA>', 'most', 'benevolent', '<COMMA>', 'ever-merciful', '<PERIOD>', 'all', 'praise', 'be', 'to', 'allah', '<COMMA>', 'lord', 'of', 'all', 'the', 'worlds', '<COMMA>', 'most', 'beneficent', '<COMMA>', 'ever-merciful', '<COMMA>', 'king', 'of']\n"
          ]
        }
      ],
      "source": [
        "# get list of words\n",
        "words = []\n",
        "for i in range(len(df.text)):\n",
        "    words = words + preprocess(df.text[i])\n",
        "print(words[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p88XUT8mWaDq",
        "outputId": "e91425ee-a8d7-4660-9b58-5e8b64ede9ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words in text: 175032\n",
            "Unique words: 6782\n"
          ]
        }
      ],
      "source": [
        "# print some stats about this word data\n",
        "print(\"Total words in text: {}\".format(len(words)))\n",
        "print(\"Unique words: {}\".format(len(set(words)))) # `set` removes any duplicate words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A5v0EDgibxNU"
      },
      "outputs": [],
      "source": [
        "def create_lookup_tables(words):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param words: Input list of words\n",
        "    :return: A tuple of dicts.  The first dict....\n",
        "    \"\"\"\n",
        "    word_counts = Counter(words)\n",
        "    # sorting the words from most to least frequent in text occurrence\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    # create int_to_vocab dictionaries\n",
        "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
        "\n",
        "    return vocab_to_int, int_to_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln0b7AEVb6d5",
        "outputId": "9162d0f5-607a-4898-cc48-3e63a5a20ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 1, 321, 4, 1973, 0, 187, 1177, 0, 1019, 2, 55, 362, 26, 6, 1973, 0, 35, 4, 55, 1, 376, 0, 187, 2943, 0, 1019, 0, 765, 4]\n"
          ]
        }
      ],
      "source": [
        "vocab_to_int, int_to_vocab = create_lookup_tables(words)\n",
        "int_words = [vocab_to_int[word] for word in words]\n",
        "\n",
        "print(int_words[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEL_yCJJb8RK",
        "outputId": "ac331c2c-68a8-4132-ea8c-36e0dab0dca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1973, 1019, 35, 2943, 1019, 765, 58, 35, 416, 866, 913, 914, 766, 324, 2944, 12, 363, 74, 180, 72, 6, 493, 9, 195, 1020, 55, 1021, 148, 2945, 3973]\n"
          ]
        }
      ],
      "source": [
        "threshold = 1e-5\n",
        "word_counts = Counter(int_words)\n",
        "\n",
        "total_count = len(int_words)\n",
        "freqs = {word: count/total_count for word, count in word_counts.items()}\n",
        "p_drop = {word: 1 - np.sqrt(threshold/freqs[word]) for word in word_counts}\n",
        "\n",
        "# discard some frequent words, according to the subsampling equation\n",
        "# create a new list of words for training\n",
        "train_words = [word for word in int_words if random.random() < (1 - p_drop[word])]\n",
        "\n",
        "print(train_words[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZKTl03Ftb_n6"
      },
      "outputs": [],
      "source": [
        "def get_target(words, idx, window_size=5):\n",
        "    ''' Get a list of words in a window around an index. '''\n",
        "    \n",
        "    R = np.random.randint(1, window_size+1)\n",
        "    start = idx - R if (idx - R) > 0 else 0\n",
        "    stop = idx + R\n",
        "    target_words = words[start:idx] + words[idx+1:stop+1]\n",
        "    \n",
        "    return list(target_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2sLPXGycHyV",
        "outputId": "cb8ab50d-a469-4412-859b-242304c3567e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Target:  [4, 6]\n"
          ]
        }
      ],
      "source": [
        "# test your code!\n",
        "\n",
        "# run this cell multiple times to check for random window selection\n",
        "int_text = [i for i in range(10)]\n",
        "print('Input: ', int_text)\n",
        "idx=5 # word index of interest\n",
        "\n",
        "target = get_target(int_text, idx=idx, window_size=2)\n",
        "print('Target: ', target)  # you should get some indices around the idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QFT1zcsucTA_"
      },
      "outputs": [],
      "source": [
        "def get_batches(words, batch_size, window_size=5):\n",
        "    ''' Create a generator of word batches as a tuple (inputs, targets) '''\n",
        "    \n",
        "    n_batches = len(words)//batch_size\n",
        "    \n",
        "    # only full batches\n",
        "    words = words[:n_batches*batch_size]\n",
        "    \n",
        "    for idx in range(0, len(words), batch_size):\n",
        "        x, y = [], []\n",
        "        batch = words[idx:idx+batch_size]\n",
        "        for ii in range(len(batch)):\n",
        "            batch_x = batch[ii]\n",
        "            batch_y = get_target(batch, ii, window_size)\n",
        "            y.extend(batch_y)\n",
        "            x.extend([batch_x]*len(batch_y))\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPEi7jd5cWEm",
        "outputId": "ce71af3a-01bc-4658-af48-a5275c18190a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x\n",
            " [0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 3]\n",
            "y\n",
            " [1, 2, 3, 0, 2, 3, 1, 3, 0, 1, 2]\n"
          ]
        }
      ],
      "source": [
        "int_text = [i for i in range(20)]\n",
        "x,y = next(get_batches(int_text, batch_size=4, window_size=5))\n",
        "\n",
        "print('x\\n', x)\n",
        "print('y\\n', y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iAHebyttcYnN"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(embedding, valid_size=16, valid_window=100, device='cpu'):\n",
        "    \"\"\" Returns the cosine similarity of validation words with words in the embedding matrix.\n",
        "        Here, embedding should be a PyTorch embedding module.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Here we're calculating the cosine similarity between some random words and \n",
        "    # our embedding vectors. With the similarities, we can look at what words are\n",
        "    # close to our random words.\n",
        "    \n",
        "    # sim = (a . b) / |a||b|\n",
        "    \n",
        "    embed_vectors = embedding.weight\n",
        "    \n",
        "    # magnitude of embedding vectors, |b|\n",
        "    magnitudes = embed_vectors.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
        "    \n",
        "    # pick N words from our ranges (0,window) and (1000,1000+window). lower id implies more frequent \n",
        "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
        "    valid_examples = np.append(valid_examples,\n",
        "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
        "    valid_examples = torch.LongTensor(valid_examples).to(device)\n",
        "    \n",
        "    valid_vectors = embedding(valid_examples)\n",
        "    similarities = torch.mm(valid_vectors, embed_vectors.t())/magnitudes\n",
        "        \n",
        "    return valid_examples, similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZtGIhiswccBN"
      },
      "outputs": [],
      "source": [
        "class SkipGramNeg(nn.Module):\n",
        "    def __init__(self, n_vocab, n_embed, noise_dist=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_vocab = n_vocab\n",
        "        self.n_embed = n_embed\n",
        "        self.noise_dist = noise_dist\n",
        "        \n",
        "        # define embedding layers for input and output words\n",
        "        self.in_embed = nn.Embedding(n_vocab, n_embed)\n",
        "        self.out_embed = nn.Embedding(n_vocab, n_embed)\n",
        "        \n",
        "        # Initialize both embedding tables with uniform distribution\n",
        "        self.in_embed.weight.data.uniform_(-1, 1)\n",
        "        self.out_embed.weight.data.uniform_(-1, 1)\n",
        "        \n",
        "    def forward_input(self, input_words):\n",
        "        # return input vector embeddings\n",
        "\n",
        "        return self.in_embed(input_words)\n",
        "    \n",
        "    def forward_output(self, output_words):\n",
        "        # return output vector embeddings\n",
        "\n",
        "        return self.out_embed(output_words)\n",
        "    \n",
        "    def forward_noise(self, batch_size, n_samples):\n",
        "        \"\"\" Generate noise vectors with shape (batch_size, n_samples, n_embed)\"\"\"\n",
        "        if self.noise_dist is None:\n",
        "            # Sample words uniformly\n",
        "            noise_dist = torch.ones(self.n_vocab)\n",
        "        else:\n",
        "            noise_dist = self.noise_dist\n",
        "            \n",
        "        # Sample words from our noise distribution\n",
        "        noise_words = torch.multinomial(noise_dist,\n",
        "                                        batch_size * n_samples,\n",
        "                                        replacement=True)\n",
        "        \n",
        "        device = \"cuda\" if model.out_embed.weight.is_cuda else \"cpu\"\n",
        "        noise_words = noise_words.to(device)\n",
        "        \n",
        "        ## TODO: get the noise embeddings\n",
        "        # reshape the embeddings so that they have dims (batch_size, n_samples, n_embed)\n",
        "        noise_words = self.out_embed(noise_words)\n",
        "        noise_words = noise_words.view(batch_size, n_samples, self.n_embed)\n",
        "        \n",
        "        return noise_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ACHT7SuVcd4C"
      },
      "outputs": [],
      "source": [
        "class NegativeSamplingLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input_vectors, output_vectors, noise_vectors):\n",
        "        \n",
        "        batch_size, embed_size = input_vectors.shape\n",
        "        \n",
        "        # Input vectors should be a batch of column vectors\n",
        "        input_vectors = input_vectors.view(batch_size, embed_size, 1)\n",
        "        \n",
        "        # Output vectors should be a batch of row vectors\n",
        "        output_vectors = output_vectors.view(batch_size, 1, embed_size)\n",
        "        \n",
        "        # bmm = batch matrix multiplication\n",
        "        # correct log-sigmoid loss\n",
        "        out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log()\n",
        "        out_loss = out_loss.squeeze()\n",
        "        \n",
        "        # incorrect log-sigmoid loss\n",
        "        noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()\n",
        "        noise_loss = noise_loss.squeeze().sum(1)  # sum the losses over the sample of noise vectors\n",
        "\n",
        "        # negate and sum correct and noisy log-sigmoid losses\n",
        "        # return average batch loss\n",
        "        return -(out_loss + noise_loss).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dOud85ARcg8r"
      },
      "outputs": [],
      "source": [
        "# freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WaTtRhjHcl6c",
        "outputId": "afdf2105-c01e-45b5-aa75-bdf20b5136ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5c880bd590>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Get our noise distribution\n",
        "# Using word frequencies calculated earlier in the notebook\n",
        "word_freqs = np.array(sorted(freqs.values(), reverse=True))\n",
        "unigram_dist = word_freqs/word_freqs.sum()\n",
        "noise_dist = torch.from_numpy(unigram_dist**(0.75)/np.sum(unigram_dist**(0.75)))\n",
        "\n",
        "# instantiating the model\n",
        "embedding_dim = 100\n",
        "model = SkipGramNeg(len(vocab_to_int), embedding_dim, noise_dist=noise_dist).to(device)\n",
        "\n",
        "# using the loss that we defined\n",
        "criterion = NegativeSamplingLoss() \n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "print_every = 100\n",
        "steps = 0\n",
        "epochs = 20\n",
        "loss_list = []\n",
        "\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    \n",
        "    # get our input, target batches\n",
        "    for input_words, target_words in get_batches(train_words, 10):\n",
        "        steps += 1\n",
        "        inputs, targets = torch.LongTensor(input_words), torch.LongTensor(target_words)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        \n",
        "        \n",
        "        # input, outpt, and noise vectors\n",
        "        input_vectors = model.forward_input(inputs)\n",
        "        output_vectors = model.forward_output(targets)\n",
        "        noise_vectors = model.forward_noise(inputs.shape[0], 5)\n",
        "\n",
        "        \n",
        "        # negative sampling loss\n",
        "        loss = criterion(input_vectors, output_vectors, noise_vectors)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if steps % print_every == 0:\n",
        "            loss_list.append(loss.item())\n",
        "            # print(\"Epoch: {}/{}\".format(e+1, epochs))\n",
        "            # print(\"Loss: \", loss.item()) # avg batch loss at this point in training\n",
        "            # valid_examples, valid_similarities = cosine_similarity(model.in_embed, device=device, valid_size=2)\n",
        "            # _, closest_idxs = valid_similarities.topk(6)\n",
        "\n",
        "            # valid_examples, closest_idxs = valid_examples.to('cpu'), closest_idxs.to('cpu')\n",
        "            # for ii, valid_idx in enumerate(valid_examples):\n",
        "            #     closest_words = [int_to_vocab[idx.item()] for idx in closest_idxs[ii]][1:]\n",
        "            #     print(int_to_vocab[valid_idx.item()] + \" | \" + ', '.join(closest_words))\n",
        "            \n",
        "            # print(\"...\\n\")\n",
        "plt.plot(loss_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward_input(torch.tensor(vocab_to_int[\"mothers\"], device='cuda'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc7EmAIamGW3",
        "outputId": "7271157b-8d9b-4432-d500-a613de7aee6e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0310, -0.0695,  1.2934, -1.2722,  0.8562,  0.0624,  0.4001,  0.2475,\n",
              "        -0.1739,  0.3394, -0.2248,  0.8103,  0.2845, -0.5365,  0.4851,  0.4852,\n",
              "        -0.3193,  0.2689,  0.4597, -0.6510,  0.2401, -0.1139, -0.1888,  0.4137,\n",
              "        -0.5824,  0.4342, -0.4543, -0.3339,  0.4290, -0.1358,  0.6741, -0.2944,\n",
              "        -0.4499,  0.4640, -0.0046,  0.7610,  0.4096,  0.2510,  0.4608,  1.1847,\n",
              "         0.1049,  0.3246, -0.3472, -0.4169,  0.2438, -1.0959, -0.6745,  0.2141,\n",
              "        -0.5348, -0.8630,  0.0877,  0.8143,  0.1829,  0.3622,  0.9247,  2.1238,\n",
              "         0.1531,  1.1704,  1.1729, -0.4699,  0.2394, -0.0466,  1.0105, -0.2438,\n",
              "         0.5244,  0.4583,  0.4226, -1.0771, -0.2349,  0.5683, -0.4145,  0.9681,\n",
              "        -1.1919,  0.3334, -0.8677,  0.4868, -0.3084, -0.3534,  0.4405,  0.0200,\n",
              "         0.6550, -0.5263,  0.4180, -1.6023,  0.2207,  0.5728, -1.3628,  0.4845,\n",
              "        -0.1564, -0.6122,  0.6942,  1.0083,  0.4495,  1.0087,  0.1370, -1.0232,\n",
              "         0.6172, -0.2136, -0.6705,  0.7984], device='cuda:0',\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltg2-l_Zcpek",
        "outputId": "0cb0a166-09d8-4843-e6ec-d1c8c2030bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/MyDrive/datasets/Quran_en.pt')"
      ],
      "metadata": {
        "id": "NSMrhzophq9B"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded = torch.load('/content/drive/MyDrive/datasets/Quran_en.pt')"
      ],
      "metadata": {
        "id": "lD0zp4Gei2vR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded.forward_input(torch.tensor(vocab_to_int[\"mothers\"], device='cuda'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSGtrkb0jAFi",
        "outputId": "f0b82b74-c138-4876-8e63-0f26a512be13"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0310, -0.0695,  1.2934, -1.2722,  0.8562,  0.0624,  0.4001,  0.2475,\n",
              "        -0.1739,  0.3394, -0.2248,  0.8103,  0.2845, -0.5365,  0.4851,  0.4852,\n",
              "        -0.3193,  0.2689,  0.4597, -0.6510,  0.2401, -0.1139, -0.1888,  0.4137,\n",
              "        -0.5824,  0.4342, -0.4543, -0.3339,  0.4290, -0.1358,  0.6741, -0.2944,\n",
              "        -0.4499,  0.4640, -0.0046,  0.7610,  0.4096,  0.2510,  0.4608,  1.1847,\n",
              "         0.1049,  0.3246, -0.3472, -0.4169,  0.2438, -1.0959, -0.6745,  0.2141,\n",
              "        -0.5348, -0.8630,  0.0877,  0.8143,  0.1829,  0.3622,  0.9247,  2.1238,\n",
              "         0.1531,  1.1704,  1.1729, -0.4699,  0.2394, -0.0466,  1.0105, -0.2438,\n",
              "         0.5244,  0.4583,  0.4226, -1.0771, -0.2349,  0.5683, -0.4145,  0.9681,\n",
              "        -1.1919,  0.3334, -0.8677,  0.4868, -0.3084, -0.3534,  0.4405,  0.0200,\n",
              "         0.6550, -0.5263,  0.4180, -1.6023,  0.2207,  0.5728, -1.3628,  0.4845,\n",
              "        -0.1564, -0.6122,  0.6942,  1.0083,  0.4495,  1.0087,  0.1370, -1.0232,\n",
              "         0.6172, -0.2136, -0.6705,  0.7984], device='cuda:0',\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aya_embeddings = []\n",
        "for k in range(len(df)):\n",
        "    aya_embeddings.append(torch.mean(model_loaded.forward_input(torch.tensor([vocab_to_int[i] for i in preprocess(df.text[k])],\n",
        "                                                                             device='cuda')), axis = 0).cpu().data.numpy())"
      ],
      "metadata": {
        "id": "YDOmHLobng7I"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_df = pd.DataFrame(aya_embeddings)\n",
        "embed_df['sura'] = df['sura']\n",
        "embed_df['aya'] = df['aya']\n",
        "embed_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "8SkyhRcusKxs",
        "outputId": "1876ce89-81e0-4839-e89c-3a896e9c3f16"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.130459 -0.170920 -0.130430 -0.425366  0.263938 -0.201712 -0.401716   \n",
              "1 -0.137422  0.188611 -0.318364 -0.265647  0.076292 -0.156067 -0.147548   \n",
              "2 -0.105227 -0.367590  0.057834 -0.623360  0.127633 -0.038408 -0.425345   \n",
              "3 -0.126925  0.020166  0.100932 -0.464344  0.496763 -0.215234 -0.526151   \n",
              "4 -0.060498  0.123393 -0.069733 -0.197850  0.097257 -0.048006 -0.041843   \n",
              "\n",
              "          7         8         9  ...        92        93        94        95  \\\n",
              "0 -0.177249 -0.301538  0.023005  ...  0.043766 -0.082393 -0.055821 -0.447854   \n",
              "1 -0.022625 -0.183700  0.040179  ...  0.022016 -0.072181  0.030498 -0.300821   \n",
              "2 -0.320201 -0.604526 -0.219789  ... -0.340051 -0.145041 -0.165572 -0.362329   \n",
              "3  0.088354 -0.222541  0.359380  ... -0.196931 -0.343176 -0.005231 -0.042328   \n",
              "4 -0.272861 -0.017689  0.029316  ...  0.123482 -0.000749 -0.020878 -0.352778   \n",
              "\n",
              "         96        97        98        99  sura  aya  \n",
              "0  0.080386 -0.177847 -0.070858  0.376248     1    1  \n",
              "1  0.188728 -0.014946 -0.022813  0.142978     1    2  \n",
              "2 -0.119050 -0.301679  0.071205  0.355422     1    3  \n",
              "3 -0.142382 -0.003090 -0.035455  0.143022     1    4  \n",
              "4 -0.044268 -0.035371 -0.078913  0.105660     1    5  \n",
              "\n",
              "[5 rows x 102 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fe5858a-94f1-46c8-9a81-18ecef0e4609\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>sura</th>\n",
              "      <th>aya</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.130459</td>\n",
              "      <td>-0.170920</td>\n",
              "      <td>-0.130430</td>\n",
              "      <td>-0.425366</td>\n",
              "      <td>0.263938</td>\n",
              "      <td>-0.201712</td>\n",
              "      <td>-0.401716</td>\n",
              "      <td>-0.177249</td>\n",
              "      <td>-0.301538</td>\n",
              "      <td>0.023005</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043766</td>\n",
              "      <td>-0.082393</td>\n",
              "      <td>-0.055821</td>\n",
              "      <td>-0.447854</td>\n",
              "      <td>0.080386</td>\n",
              "      <td>-0.177847</td>\n",
              "      <td>-0.070858</td>\n",
              "      <td>0.376248</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.137422</td>\n",
              "      <td>0.188611</td>\n",
              "      <td>-0.318364</td>\n",
              "      <td>-0.265647</td>\n",
              "      <td>0.076292</td>\n",
              "      <td>-0.156067</td>\n",
              "      <td>-0.147548</td>\n",
              "      <td>-0.022625</td>\n",
              "      <td>-0.183700</td>\n",
              "      <td>0.040179</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022016</td>\n",
              "      <td>-0.072181</td>\n",
              "      <td>0.030498</td>\n",
              "      <td>-0.300821</td>\n",
              "      <td>0.188728</td>\n",
              "      <td>-0.014946</td>\n",
              "      <td>-0.022813</td>\n",
              "      <td>0.142978</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.105227</td>\n",
              "      <td>-0.367590</td>\n",
              "      <td>0.057834</td>\n",
              "      <td>-0.623360</td>\n",
              "      <td>0.127633</td>\n",
              "      <td>-0.038408</td>\n",
              "      <td>-0.425345</td>\n",
              "      <td>-0.320201</td>\n",
              "      <td>-0.604526</td>\n",
              "      <td>-0.219789</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.340051</td>\n",
              "      <td>-0.145041</td>\n",
              "      <td>-0.165572</td>\n",
              "      <td>-0.362329</td>\n",
              "      <td>-0.119050</td>\n",
              "      <td>-0.301679</td>\n",
              "      <td>0.071205</td>\n",
              "      <td>0.355422</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.126925</td>\n",
              "      <td>0.020166</td>\n",
              "      <td>0.100932</td>\n",
              "      <td>-0.464344</td>\n",
              "      <td>0.496763</td>\n",
              "      <td>-0.215234</td>\n",
              "      <td>-0.526151</td>\n",
              "      <td>0.088354</td>\n",
              "      <td>-0.222541</td>\n",
              "      <td>0.359380</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.196931</td>\n",
              "      <td>-0.343176</td>\n",
              "      <td>-0.005231</td>\n",
              "      <td>-0.042328</td>\n",
              "      <td>-0.142382</td>\n",
              "      <td>-0.003090</td>\n",
              "      <td>-0.035455</td>\n",
              "      <td>0.143022</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.060498</td>\n",
              "      <td>0.123393</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>-0.197850</td>\n",
              "      <td>0.097257</td>\n",
              "      <td>-0.048006</td>\n",
              "      <td>-0.041843</td>\n",
              "      <td>-0.272861</td>\n",
              "      <td>-0.017689</td>\n",
              "      <td>0.029316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.123482</td>\n",
              "      <td>-0.000749</td>\n",
              "      <td>-0.020878</td>\n",
              "      <td>-0.352778</td>\n",
              "      <td>-0.044268</td>\n",
              "      <td>-0.035371</td>\n",
              "      <td>-0.078913</td>\n",
              "      <td>0.105660</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 102 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fe5858a-94f1-46c8-9a81-18ecef0e4609')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fe5858a-94f1-46c8-9a81-18ecef0e4609 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fe5858a-94f1-46c8-9a81-18ecef0e4609');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_df.to_csv('/content/drive/MyDrive/datasets/Quran_en_vector.csv')"
      ],
      "metadata": {
        "id": "OV9-vaQpu30H"
      },
      "execution_count": 34,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_HW_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
