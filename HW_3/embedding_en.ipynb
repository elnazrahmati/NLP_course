{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4qpa-r3M8d8",
        "outputId": "36924072-4500-4c09-8bc7-145e32077685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-28 11:58:35--  https://tanzil.net/trans/en.ahmedali\n",
            "Resolving tanzil.net (tanzil.net)... 209.95.51.187, 136.243.149.84\n",
            "Connecting to tanzil.net (tanzil.net)|209.95.51.187|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘en.ahmedali’\n",
            "\n",
            "en.ahmedali             [ <=>                ] 806.33K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-05-28 11:58:35 (7.82 MB/s) - ‘en.ahmedali’ saved [825681]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://tanzil.net/trans/en.ahmedali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "i1etby7ej4ar",
        "outputId": "523c1378-e35f-43f0-e58e-ddc911b7dc0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  sura  aya                                               text\n",
              "0    1  1.0  In the name of Allah, most benevolent, ever-me...\n",
              "1    1  2.0    ALL PRAISE BE to Allah, Lord of all the worlds,\n",
              "2    1  3.0                    Most beneficent, ever-merciful,\n",
              "3    1  4.0                      King of the Day of Judgement.\n",
              "4    1  5.0  You alone we worship, and to You alone turn fo...\n",
              "5    1  6.0    Guide us (O Lord) to the path that is straight,\n",
              "6    1  7.0  The path of those You have blessed, Not of tho...\n",
              "7    2  1.0                                      ALIF LAM MIM.\n",
              "8    2  2.0  This is The Book free of doubt and involution,...\n",
              "9    2  3.0  Who believe in the Unknown and fulfil their de..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5249898d-a30d-4cea-bf0f-08cea7e2c0aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sura</th>\n",
              "      <th>aya</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>In the name of Allah, most benevolent, ever-me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>ALL PRAISE BE to Allah, Lord of all the worlds,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Most beneficent, ever-merciful,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>King of the Day of Judgement.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>You alone we worship, and to You alone turn fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Guide us (O Lord) to the path that is straight,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>The path of those You have blessed, Not of tho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ALIF LAM MIM.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>This is The Book free of doubt and involution,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Who believe in the Unknown and fulfil their de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5249898d-a30d-4cea-bf0f-08cea7e2c0aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5249898d-a30d-4cea-bf0f-08cea7e2c0aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5249898d-a30d-4cea-bf0f-08cea7e2c0aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('en.ahmedali', sep='|', header = None, names = ['sura', 'aya', 'text'])\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rM0kBISXaqC9"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2QNUCo3lOJ4b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OEyFKIbJOKPB"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "\n",
        "    # Replace punctuation with tokens so we can use them in our model\n",
        "    text = text.lower()\n",
        "    text = text.replace('.', ' <PERIOD> ')\n",
        "    text = text.replace(',', ' <COMMA> ')\n",
        "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
        "    text = text.replace(';', ' <SEMICOLON> ')\n",
        "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
        "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    text = text.replace('(', ' <LEFT_PAREN> ')\n",
        "    text = text.replace(')', ' <RIGHT_PAREN> ')\n",
        "    text = text.replace('--', ' <HYPHENS> ')\n",
        "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "    # text = text.replace('\\n', ' <NEW_LINE> ')\n",
        "    text = text.replace(':', ' <COLON> ')\n",
        "    words = text.split()\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAtN_S3-Vfw2",
        "outputId": "c1111543-2fdf-4ec4-be86-966747b7a311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in', 'the', 'name', 'of', 'allah', '<COMMA>', 'most', 'benevolent', '<COMMA>', 'ever-merciful', '<PERIOD>', 'all', 'praise', 'be', 'to', 'allah', '<COMMA>', 'lord', 'of', 'all', 'the', 'worlds', '<COMMA>', 'most', 'beneficent', '<COMMA>', 'ever-merciful', '<COMMA>', 'king', 'of']\n"
          ]
        }
      ],
      "source": [
        "# get list of words\n",
        "words = []\n",
        "for i in range(len(df.text)):\n",
        "    words = words + preprocess(df.text[i])\n",
        "print(words[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p88XUT8mWaDq",
        "outputId": "c442e178-e956-40fc-aab8-c6247bb3dd86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words in text: 174714\n",
            "Unique words: 6839\n"
          ]
        }
      ],
      "source": [
        "# print some stats about this word data\n",
        "print(\"Total words in text: {}\".format(len(words)))\n",
        "print(\"Unique words: {}\".format(len(set(words)))) # `set` removes any duplicate words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "A5v0EDgibxNU"
      },
      "outputs": [],
      "source": [
        "def create_lookup_tables(words):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param words: Input list of words\n",
        "    :return: A tuple of dicts.  The first dict....\n",
        "    \"\"\"\n",
        "    word_counts = Counter(words)\n",
        "    # sorting the words from most to least frequent in text occurrence\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    # create int_to_vocab dictionaries\n",
        "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
        "\n",
        "    return vocab_to_int, int_to_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln0b7AEVb6d5",
        "outputId": "40ae7174-8e5b-4894-d025-2fb2c815dab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 1, 321, 4, 1973, 0, 187, 1177, 0, 1019, 2, 55, 362, 26, 6, 1973, 0, 35, 4, 55, 1, 376, 0, 187, 2943, 0, 1019, 0, 765, 4]\n"
          ]
        }
      ],
      "source": [
        "vocab_to_int, int_to_vocab = create_lookup_tables(words)\n",
        "int_words = [vocab_to_int[word] for word in words]\n",
        "\n",
        "print(int_words[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEL_yCJJb8RK",
        "outputId": "8b297717-bbeb-445b-fd0a-8405bb8ac9dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1973, 55, 362, 2943, 234, 23, 96, 914, 766, 324, 2944, 195, 473, 30, 444, 363, 57, 180, 1020, 2, 1021, 30, 538, 2945, 3972, 733, 1096, 1096, 1178, 1097]\n"
          ]
        }
      ],
      "source": [
        "threshold = 1e-5\n",
        "word_counts = Counter(int_words)\n",
        "\n",
        "total_count = len(int_words)\n",
        "freqs = {word: count/total_count for word, count in word_counts.items()}\n",
        "p_drop = {word: 1 - np.sqrt(threshold/freqs[word]) for word in word_counts}\n",
        "\n",
        "# discard some frequent words, according to the subsampling equation\n",
        "# create a new list of words for training\n",
        "train_words = [word for word in int_words if random.random() < (1 - p_drop[word])]\n",
        "\n",
        "print(train_words[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZKTl03Ftb_n6"
      },
      "outputs": [],
      "source": [
        "def get_target(words, idx, window_size=5):\n",
        "    ''' Get a list of words in a window around an index. '''\n",
        "    \n",
        "    R = np.random.randint(1, window_size+1)\n",
        "    start = idx - R if (idx - R) > 0 else 0\n",
        "    stop = idx + R\n",
        "    target_words = words[start:idx] + words[idx+1:stop+1]\n",
        "    \n",
        "    return list(target_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2sLPXGycHyV",
        "outputId": "40a78339-fb44-4283-c383-9c78fcf5f629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "Target:  [4, 6]\n"
          ]
        }
      ],
      "source": [
        "# test your code!\n",
        "\n",
        "# run this cell multiple times to check for random window selection\n",
        "int_text = [i for i in range(10)]\n",
        "print('Input: ', int_text)\n",
        "idx=5 # word index of interest\n",
        "\n",
        "target = get_target(int_text, idx=idx, window_size=2)\n",
        "print('Target: ', target)  # you should get some indices around the idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QFT1zcsucTA_"
      },
      "outputs": [],
      "source": [
        "def get_batches(words, batch_size, window_size=5):\n",
        "    ''' Create a generator of word batches as a tuple (inputs, targets) '''\n",
        "    \n",
        "    n_batches = len(words)//batch_size\n",
        "    \n",
        "    # only full batches\n",
        "    words = words[:n_batches*batch_size]\n",
        "    \n",
        "    for idx in range(0, len(words), batch_size):\n",
        "        x, y = [], []\n",
        "        batch = words[idx:idx+batch_size]\n",
        "        for ii in range(len(batch)):\n",
        "            batch_x = batch[ii]\n",
        "            batch_y = get_target(batch, ii, window_size)\n",
        "            y.extend(batch_y)\n",
        "            x.extend([batch_x]*len(batch_y))\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPEi7jd5cWEm",
        "outputId": "57ec1fd0-0734-4b0d-82cf-c74391dca002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x\n",
            " [0, 0, 0, 1, 1, 2, 2, 3, 3, 3]\n",
            "y\n",
            " [1, 2, 3, 0, 2, 1, 3, 0, 1, 2]\n"
          ]
        }
      ],
      "source": [
        "int_text = [i for i in range(20)]\n",
        "x,y = next(get_batches(int_text, batch_size=4, window_size=5))\n",
        "\n",
        "print('x\\n', x)\n",
        "print('y\\n', y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iAHebyttcYnN"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(embedding, valid_size=16, valid_window=100, device='cpu'):\n",
        "    \"\"\" Returns the cosine similarity of validation words with words in the embedding matrix.\n",
        "        Here, embedding should be a PyTorch embedding module.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Here we're calculating the cosine similarity between some random words and \n",
        "    # our embedding vectors. With the similarities, we can look at what words are\n",
        "    # close to our random words.\n",
        "    \n",
        "    # sim = (a . b) / |a||b|\n",
        "    \n",
        "    embed_vectors = embedding.weight\n",
        "    \n",
        "    # magnitude of embedding vectors, |b|\n",
        "    magnitudes = embed_vectors.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
        "    \n",
        "    # pick N words from our ranges (0,window) and (1000,1000+window). lower id implies more frequent \n",
        "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
        "    valid_examples = np.append(valid_examples,\n",
        "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
        "    valid_examples = torch.LongTensor(valid_examples).to(device)\n",
        "    \n",
        "    valid_vectors = embedding(valid_examples)\n",
        "    similarities = torch.mm(valid_vectors, embed_vectors.t())/magnitudes\n",
        "        \n",
        "    return valid_examples, similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZtGIhiswccBN"
      },
      "outputs": [],
      "source": [
        "class SkipGramNeg(nn.Module):\n",
        "    def __init__(self, n_vocab, n_embed, noise_dist=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_vocab = n_vocab\n",
        "        self.n_embed = n_embed\n",
        "        self.noise_dist = noise_dist\n",
        "        \n",
        "        # define embedding layers for input and output words\n",
        "        self.in_embed = nn.Embedding(n_vocab, n_embed)\n",
        "        self.out_embed = nn.Embedding(n_vocab, n_embed)\n",
        "        \n",
        "        # Initialize both embedding tables with uniform distribution\n",
        "        self.in_embed.weight.data.uniform_(-1, 1)\n",
        "        self.out_embed.weight.data.uniform_(-1, 1)\n",
        "        \n",
        "    def forward_input(self, input_words):\n",
        "        # return input vector embeddings\n",
        "\n",
        "        return self.in_embed(input_words)\n",
        "    \n",
        "    def forward_output(self, output_words):\n",
        "        # return output vector embeddings\n",
        "\n",
        "        return self.out_embed(output_words)\n",
        "    \n",
        "    def forward_noise(self, batch_size, n_samples):\n",
        "        \"\"\" Generate noise vectors with shape (batch_size, n_samples, n_embed)\"\"\"\n",
        "        if self.noise_dist is None:\n",
        "            # Sample words uniformly\n",
        "            noise_dist = torch.ones(self.n_vocab)\n",
        "        else:\n",
        "            noise_dist = self.noise_dist\n",
        "            \n",
        "        # Sample words from our noise distribution\n",
        "        noise_words = torch.multinomial(noise_dist,\n",
        "                                        batch_size * n_samples,\n",
        "                                        replacement=True)\n",
        "        \n",
        "        device = \"cuda\" if model.out_embed.weight.is_cuda else \"cpu\"\n",
        "        noise_words = noise_words.to(device)\n",
        "        \n",
        "        ## TODO: get the noise embeddings\n",
        "        # reshape the embeddings so that they have dims (batch_size, n_samples, n_embed)\n",
        "        noise_words = self.out_embed(noise_words)\n",
        "        noise_words = noise_words.view(batch_size, n_samples, self.n_embed)\n",
        "        \n",
        "        return noise_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ACHT7SuVcd4C"
      },
      "outputs": [],
      "source": [
        "class NegativeSamplingLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input_vectors, output_vectors, noise_vectors):\n",
        "        \n",
        "        batch_size, embed_size = input_vectors.shape\n",
        "        \n",
        "        # Input vectors should be a batch of column vectors\n",
        "        input_vectors = input_vectors.view(batch_size, embed_size, 1)\n",
        "        \n",
        "        # Output vectors should be a batch of row vectors\n",
        "        output_vectors = output_vectors.view(batch_size, 1, embed_size)\n",
        "        \n",
        "        # bmm = batch matrix multiplication\n",
        "        # correct log-sigmoid loss\n",
        "        out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log()\n",
        "        out_loss = out_loss.squeeze()\n",
        "        \n",
        "        # incorrect log-sigmoid loss\n",
        "        noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()\n",
        "        noise_loss = noise_loss.squeeze().sum(1)  # sum the losses over the sample of noise vectors\n",
        "\n",
        "        # negate and sum correct and noisy log-sigmoid losses\n",
        "        # return average batch loss\n",
        "        return -(out_loss + noise_loss).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dOud85ARcg8r"
      },
      "outputs": [],
      "source": [
        "# freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WaTtRhjHcl6c",
        "outputId": "9155cb91-3a44-4705-9c64-a3538d0a6f60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4c818ab750>]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Get our noise distribution\n",
        "# Using word frequencies calculated earlier in the notebook\n",
        "word_freqs = np.array(sorted(freqs.values(), reverse=True))\n",
        "unigram_dist = word_freqs/word_freqs.sum()\n",
        "noise_dist = torch.from_numpy(unigram_dist**(0.75)/np.sum(unigram_dist**(0.75)))\n",
        "\n",
        "# instantiating the model\n",
        "embedding_dim = 100\n",
        "model = SkipGramNeg(len(vocab_to_int), embedding_dim, noise_dist=noise_dist).to(device)\n",
        "\n",
        "# using the loss that we defined\n",
        "criterion = NegativeSamplingLoss() \n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "print_every = 100\n",
        "steps = 0\n",
        "epochs = 20\n",
        "loss_list = []\n",
        "\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    \n",
        "    # get our input, target batches\n",
        "    for input_words, target_words in get_batches(train_words, 10):\n",
        "        steps += 1\n",
        "        inputs, targets = torch.LongTensor(input_words), torch.LongTensor(target_words)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        \n",
        "        \n",
        "        # input, outpt, and noise vectors\n",
        "        input_vectors = model.forward_input(inputs)\n",
        "        output_vectors = model.forward_output(targets)\n",
        "        noise_vectors = model.forward_noise(inputs.shape[0], 5)\n",
        "\n",
        "        \n",
        "        # negative sampling loss\n",
        "        loss = criterion(input_vectors, output_vectors, noise_vectors)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if steps % print_every == 0:\n",
        "            loss_list.append(loss.item())\n",
        "            # print(\"Epoch: {}/{}\".format(e+1, epochs))\n",
        "            # print(\"Loss: \", loss.item()) # avg batch loss at this point in training\n",
        "            # valid_examples, valid_similarities = cosine_similarity(model.in_embed, device=device, valid_size=2)\n",
        "            # _, closest_idxs = valid_similarities.topk(6)\n",
        "\n",
        "            # valid_examples, closest_idxs = valid_examples.to('cpu'), closest_idxs.to('cpu')\n",
        "            # for ii, valid_idx in enumerate(valid_examples):\n",
        "            #     closest_words = [int_to_vocab[idx.item()] for idx in closest_idxs[ii]][1:]\n",
        "            #     print(int_to_vocab[valid_idx.item()] + \" | \" + ', '.join(closest_words))\n",
        "            \n",
        "            # print(\"...\\n\")\n",
        "plt.plot(loss_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward_input(torch.tensor(vocab_to_int[\"mothers\"], device='cuda'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc7EmAIamGW3",
        "outputId": "3f83e1aa-cd2c-4498-87c8-097346efc950"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0799, -0.4095,  0.4059,  0.4463,  0.4868, -0.3048, -0.4143, -0.7366,\n",
              "        -0.3123,  0.1727, -0.3971, -0.8963, -0.0301,  0.2651,  0.0601,  0.7980,\n",
              "         0.4117, -0.2739, -0.8731, -0.0278,  0.1592,  0.1143,  1.7546, -0.2426,\n",
              "        -0.4289, -1.2346,  0.1374,  0.9098,  0.4386,  1.2200,  1.5876, -1.6960,\n",
              "         0.1636,  0.1711, -0.1022,  0.0806,  0.7428,  0.4316, -0.1172, -0.8371,\n",
              "         0.6711,  0.1278, -0.5413, -0.8086, -0.7296,  0.3581, -0.3696, -0.3800,\n",
              "         0.1998, -0.4308, -1.4394, -0.1206, -0.9911,  0.5038,  0.0835, -0.3584,\n",
              "        -0.1068, -0.0583,  0.9075,  0.6643,  1.6945,  0.4066,  0.1079,  0.1887,\n",
              "        -0.0957, -0.8895,  0.7354,  0.4541,  0.7257,  0.6405, -1.3912,  1.2962,\n",
              "         0.8243, -0.6915,  0.3288,  0.1232,  0.3831, -0.6902,  0.0732,  1.3371,\n",
              "         0.5442, -0.0361, -0.0519, -0.0375,  0.5343, -0.7212, -0.7182,  1.1606,\n",
              "         0.8336,  0.2497, -0.7717,  0.3895,  1.3965, -0.1732,  0.4752,  1.1775,\n",
              "         0.7262,  1.0633, -1.2305,  0.0186], device='cuda:0',\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ltg2-l_Zcpek"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/MyDrive/datasets/Quran_en.pt')"
      ],
      "metadata": {
        "id": "NSMrhzophq9B"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded = torch.load('/content/drive/MyDrive/datasets/Quran_en.pt')"
      ],
      "metadata": {
        "id": "lD0zp4Gei2vR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded.forward_input(torch.tensor(vocab_to_int[\"mothers\"], device='cuda'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSGtrkb0jAFi",
        "outputId": "b0302265-6759-40e9-eab6-de2263188b9f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0799, -0.4095,  0.4059,  0.4463,  0.4868, -0.3048, -0.4143, -0.7366,\n",
              "        -0.3123,  0.1727, -0.3971, -0.8963, -0.0301,  0.2651,  0.0601,  0.7980,\n",
              "         0.4117, -0.2739, -0.8731, -0.0278,  0.1592,  0.1143,  1.7546, -0.2426,\n",
              "        -0.4289, -1.2346,  0.1374,  0.9098,  0.4386,  1.2200,  1.5876, -1.6960,\n",
              "         0.1636,  0.1711, -0.1022,  0.0806,  0.7428,  0.4316, -0.1172, -0.8371,\n",
              "         0.6711,  0.1278, -0.5413, -0.8086, -0.7296,  0.3581, -0.3696, -0.3800,\n",
              "         0.1998, -0.4308, -1.4394, -0.1206, -0.9911,  0.5038,  0.0835, -0.3584,\n",
              "        -0.1068, -0.0583,  0.9075,  0.6643,  1.6945,  0.4066,  0.1079,  0.1887,\n",
              "        -0.0957, -0.8895,  0.7354,  0.4541,  0.7257,  0.6405, -1.3912,  1.2962,\n",
              "         0.8243, -0.6915,  0.3288,  0.1232,  0.3831, -0.6902,  0.0732,  1.3371,\n",
              "         0.5442, -0.0361, -0.0519, -0.0375,  0.5343, -0.7212, -0.7182,  1.1606,\n",
              "         0.8336,  0.2497, -0.7717,  0.3895,  1.3965, -0.1732,  0.4752,  1.1775,\n",
              "         0.7262,  1.0633, -1.2305,  0.0186], device='cuda:0',\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aya_embeddings = []\n",
        "for k in range(len(df)):\n",
        "    aya_embeddings.append(torch.mean(model_loaded.forward_input(torch.tensor([vocab_to_int[i] for i in preprocess(df.text[k])],\n",
        "                                                                             device='cuda')), axis = 0).cpu().data.numpy())"
      ],
      "metadata": {
        "id": "YDOmHLobng7I"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_df = pd.DataFrame(aya_embeddings)\n",
        "embed_df['sura'] = df['sura']\n",
        "embed_df['aya'] = df['aya']\n",
        "embed_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "8SkyhRcusKxs",
        "outputId": "138aba9a-79bb-43b1-f192-bbe0f52329a4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.171514 -0.489629  0.254018 -0.349966  0.242573  0.046392 -0.299897   \n",
              "1 -0.021678 -0.375802  0.359136 -0.177212  0.114209 -0.131925 -0.334276   \n",
              "2 -0.118067 -0.338964  0.298802 -0.657549  0.428781 -0.012544 -0.251017   \n",
              "3 -0.448647 -0.660770  0.173458 -0.140854  0.375912  0.163701  0.093526   \n",
              "4 -0.198228 -0.121813  0.260619 -0.262711  0.161585 -0.299900 -0.068394   \n",
              "\n",
              "          7         8         9  ...        92        93        94        95  \\\n",
              "0  0.163359  0.423348 -0.066725  ...  0.120619 -0.057924  0.049006  0.040683   \n",
              "1  0.229525  0.292004  0.086102  ... -0.153934  0.053150  0.141918 -0.026183   \n",
              "2 -0.064933  0.653962 -0.171747  ...  0.331433  0.117913  0.480295  0.015860   \n",
              "3 -0.060421  0.246622 -0.060870  ...  0.157528 -0.100647  0.068364 -0.311591   \n",
              "4  0.051948  0.149693 -0.158854  ...  0.292382  0.142450 -0.026946  0.087359   \n",
              "\n",
              "         96        97        98        99  sura  aya  \n",
              "0 -0.039895  0.086589 -0.435853  0.249744     1  1.0  \n",
              "1 -0.068479  0.362046 -0.390885 -0.224058     1  2.0  \n",
              "2  0.137706  0.259734 -0.402255  0.482192     1  3.0  \n",
              "3 -0.275776  0.374612 -0.256142 -0.046475     1  4.0  \n",
              "4 -0.101181  0.407066 -0.244840 -0.274381     1  5.0  \n",
              "\n",
              "[5 rows x 102 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5c665ec-6bd7-454e-beee-a00283b28b0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>sura</th>\n",
              "      <th>aya</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.171514</td>\n",
              "      <td>-0.489629</td>\n",
              "      <td>0.254018</td>\n",
              "      <td>-0.349966</td>\n",
              "      <td>0.242573</td>\n",
              "      <td>0.046392</td>\n",
              "      <td>-0.299897</td>\n",
              "      <td>0.163359</td>\n",
              "      <td>0.423348</td>\n",
              "      <td>-0.066725</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120619</td>\n",
              "      <td>-0.057924</td>\n",
              "      <td>0.049006</td>\n",
              "      <td>0.040683</td>\n",
              "      <td>-0.039895</td>\n",
              "      <td>0.086589</td>\n",
              "      <td>-0.435853</td>\n",
              "      <td>0.249744</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.021678</td>\n",
              "      <td>-0.375802</td>\n",
              "      <td>0.359136</td>\n",
              "      <td>-0.177212</td>\n",
              "      <td>0.114209</td>\n",
              "      <td>-0.131925</td>\n",
              "      <td>-0.334276</td>\n",
              "      <td>0.229525</td>\n",
              "      <td>0.292004</td>\n",
              "      <td>0.086102</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.153934</td>\n",
              "      <td>0.053150</td>\n",
              "      <td>0.141918</td>\n",
              "      <td>-0.026183</td>\n",
              "      <td>-0.068479</td>\n",
              "      <td>0.362046</td>\n",
              "      <td>-0.390885</td>\n",
              "      <td>-0.224058</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.118067</td>\n",
              "      <td>-0.338964</td>\n",
              "      <td>0.298802</td>\n",
              "      <td>-0.657549</td>\n",
              "      <td>0.428781</td>\n",
              "      <td>-0.012544</td>\n",
              "      <td>-0.251017</td>\n",
              "      <td>-0.064933</td>\n",
              "      <td>0.653962</td>\n",
              "      <td>-0.171747</td>\n",
              "      <td>...</td>\n",
              "      <td>0.331433</td>\n",
              "      <td>0.117913</td>\n",
              "      <td>0.480295</td>\n",
              "      <td>0.015860</td>\n",
              "      <td>0.137706</td>\n",
              "      <td>0.259734</td>\n",
              "      <td>-0.402255</td>\n",
              "      <td>0.482192</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.448647</td>\n",
              "      <td>-0.660770</td>\n",
              "      <td>0.173458</td>\n",
              "      <td>-0.140854</td>\n",
              "      <td>0.375912</td>\n",
              "      <td>0.163701</td>\n",
              "      <td>0.093526</td>\n",
              "      <td>-0.060421</td>\n",
              "      <td>0.246622</td>\n",
              "      <td>-0.060870</td>\n",
              "      <td>...</td>\n",
              "      <td>0.157528</td>\n",
              "      <td>-0.100647</td>\n",
              "      <td>0.068364</td>\n",
              "      <td>-0.311591</td>\n",
              "      <td>-0.275776</td>\n",
              "      <td>0.374612</td>\n",
              "      <td>-0.256142</td>\n",
              "      <td>-0.046475</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.198228</td>\n",
              "      <td>-0.121813</td>\n",
              "      <td>0.260619</td>\n",
              "      <td>-0.262711</td>\n",
              "      <td>0.161585</td>\n",
              "      <td>-0.299900</td>\n",
              "      <td>-0.068394</td>\n",
              "      <td>0.051948</td>\n",
              "      <td>0.149693</td>\n",
              "      <td>-0.158854</td>\n",
              "      <td>...</td>\n",
              "      <td>0.292382</td>\n",
              "      <td>0.142450</td>\n",
              "      <td>-0.026946</td>\n",
              "      <td>0.087359</td>\n",
              "      <td>-0.101181</td>\n",
              "      <td>0.407066</td>\n",
              "      <td>-0.244840</td>\n",
              "      <td>-0.274381</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 102 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5c665ec-6bd7-454e-beee-a00283b28b0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5c665ec-6bd7-454e-beee-a00283b28b0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5c665ec-6bd7-454e-beee-a00283b28b0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_df.to_csv('/content/drive/MyDrive/datasets/Quran_en_vector.csv')"
      ],
      "metadata": {
        "id": "OV9-vaQpu30H"
      },
      "execution_count": 67,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_HW_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}