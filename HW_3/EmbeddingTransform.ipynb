{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mapping Embedding spaces"
      ],
      "metadata": {
        "id": "41erm9H79v4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsx1nLe05PDz",
        "outputId": "19b1efc4-594a-48eb-ab7c-2a1a9df76850"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pdqHaYZ75wYA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from numpy.linalg import norm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### this functoin normalizes embedding vectors"
      ],
      "metadata": {
        "id": "gjoLFnQE9uPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "def normalizer (df) :\n",
        "\n",
        "  df = df.drop(columns=['sura', 'aya']) \n",
        "  df = df.drop(df.columns[[0]], axis=1) \n",
        "  normal = normalize(df.to_numpy(), axis=1, norm='l2')\n",
        "\n",
        "  return torch.from_numpy(normal)"
      ],
      "metadata": {
        "id": "XIEKrdbbF5EC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### for shuffling indexes in the case split data to train and validation"
      ],
      "metadata": {
        "id": "WDPVLvml94xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_index(tensor1, tensor2) :\n",
        "\n",
        "  res = torch.cat((tensor1, tensor2), 1)\n",
        "  res = pd.DataFrame(res.numpy())\n",
        "  return res.sample(frac = 1)  "
      ],
      "metadata": {
        "id": "yo7yEcvGHO7c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load embedding of different languages, normalize them and convert dataframes to Tensors"
      ],
      "metadata": {
        "id": "L_3gNRxr9_uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading embeddings\n",
        "df = pd.read_csv('drive/MyDrive/Sources/Quran_en_vector.csv')\n",
        "df1 = pd.read_csv('drive/MyDrive/Sources/arabian_embeddings.csv')\n",
        "df2 = pd.read_csv('drive/MyDrive/Sources/persina_embeddings.csv')\n",
        "\n",
        "print(df.shape)\n",
        "print(df1.shape)\n",
        "print(df2.shape)\n",
        "\n",
        "########### normalize embedding vectors and convert them to tensors ############\n",
        "en = normalizer(df)\n",
        "ar = normalizer(df1)\n",
        "fa = normalizer(df2)\n",
        "\n",
        "df\n",
        "\n",
        "\n",
        "####################### shuffle indexes for train/val###########################\n",
        "#shuffled = shuffle_index(fa, en)\n",
        "#shuffled\n",
        "\n",
        "#train_idx = shuffled.iloc[:4000, :].index\n",
        "#test_idx = shuffled.iloc[4000:, :].index\n",
        "\n",
        "#X = torch.from_numpy(train_idx.iloc[:, :100].to_numpy())\n",
        "#Y = torch.from_numpy(train_idx.iloc[:, 100:].to_numpy())\n",
        "################################################################################\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "oDSV6mCYnmrB",
        "outputId": "8029c779-3ecc-4da0-9214-ee563ba41e01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6236, 103)\n",
            "(6236, 103)\n",
            "(6236, 103)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0         0         1         2         3         4         5  \\\n",
              "0              0  0.130459 -0.170920 -0.130430 -0.425366  0.263938 -0.201712   \n",
              "1              1 -0.137422  0.188611 -0.318364 -0.265647  0.076292 -0.156067   \n",
              "2              2 -0.105227 -0.367590  0.057834 -0.623360  0.127633 -0.038408   \n",
              "3              3 -0.126925  0.020166  0.100932 -0.464344  0.496763 -0.215234   \n",
              "4              4 -0.060498  0.123393 -0.069733 -0.197850  0.097257 -0.048006   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "6231        6231 -0.077220 -0.161203  0.018463 -0.457005  0.416739  0.028342   \n",
              "6232        6232 -0.032591  0.205356  0.195381 -0.296000  0.302850 -0.017343   \n",
              "6233        6233 -0.094378  0.350528 -0.063975 -0.493669  0.322647 -0.105747   \n",
              "6234        6234 -0.057526  0.246342 -0.407510 -0.405858  0.120783 -0.312137   \n",
              "6235        6235 -0.028098  0.238066 -0.148074 -0.105361  0.205518 -0.250160   \n",
              "\n",
              "             6         7         8  ...        92        93        94  \\\n",
              "0    -0.401716 -0.177249 -0.301538  ...  0.043766 -0.082393 -0.055821   \n",
              "1    -0.147548 -0.022625 -0.183700  ...  0.022016 -0.072181  0.030498   \n",
              "2    -0.425345 -0.320201 -0.604526  ... -0.340051 -0.145041 -0.165572   \n",
              "3    -0.526151  0.088354 -0.222541  ... -0.196931 -0.343176 -0.005231   \n",
              "4    -0.041843 -0.272861 -0.017689  ...  0.123482 -0.000749 -0.020878   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "6231 -0.353683  0.014565 -0.536690  ... -0.317391 -0.395045  0.061353   \n",
              "6232 -0.317731  0.061563 -0.385725  ... -0.159178 -0.255210  0.135381   \n",
              "6233 -0.243063  0.020720 -0.429954  ... -0.072447 -0.226918  0.047581   \n",
              "6234 -0.258789 -0.029895 -0.563389  ...  0.075562 -0.109152  0.039109   \n",
              "6235 -0.338060 -0.161969 -0.428494  ...  0.089525 -0.020102 -0.012357   \n",
              "\n",
              "            95        96        97        98        99  sura  aya  \n",
              "0    -0.447854  0.080386 -0.177847 -0.070858  0.376248     1    1  \n",
              "1    -0.300821  0.188728 -0.014946 -0.022813  0.142978     1    2  \n",
              "2    -0.362329 -0.119050 -0.301679  0.071205  0.355422     1    3  \n",
              "3    -0.042328 -0.142382 -0.003090 -0.035455  0.143022     1    4  \n",
              "4    -0.352778 -0.044268 -0.035371 -0.078913  0.105660     1    5  \n",
              "...        ...       ...       ...       ...       ...   ...  ...  \n",
              "6231 -0.082348 -0.025392 -0.158036  0.239290  0.021167   114    2  \n",
              "6232 -0.090296 -0.139390  0.081853  0.071966  0.129449   114    3  \n",
              "6233 -0.024180 -0.108588  0.060664  0.068632  0.147306   114    4  \n",
              "6234 -0.225467 -0.039532  0.263450 -0.150685  0.219159   114    5  \n",
              "6235 -0.192801  0.043596  0.155213  0.013843  0.191052   114    6  \n",
              "\n",
              "[6236 rows x 103 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a37d47f8-6375-4de6-afd9-8ba2ab5188cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>sura</th>\n",
              "      <th>aya</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.130459</td>\n",
              "      <td>-0.170920</td>\n",
              "      <td>-0.130430</td>\n",
              "      <td>-0.425366</td>\n",
              "      <td>0.263938</td>\n",
              "      <td>-0.201712</td>\n",
              "      <td>-0.401716</td>\n",
              "      <td>-0.177249</td>\n",
              "      <td>-0.301538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043766</td>\n",
              "      <td>-0.082393</td>\n",
              "      <td>-0.055821</td>\n",
              "      <td>-0.447854</td>\n",
              "      <td>0.080386</td>\n",
              "      <td>-0.177847</td>\n",
              "      <td>-0.070858</td>\n",
              "      <td>0.376248</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.137422</td>\n",
              "      <td>0.188611</td>\n",
              "      <td>-0.318364</td>\n",
              "      <td>-0.265647</td>\n",
              "      <td>0.076292</td>\n",
              "      <td>-0.156067</td>\n",
              "      <td>-0.147548</td>\n",
              "      <td>-0.022625</td>\n",
              "      <td>-0.183700</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022016</td>\n",
              "      <td>-0.072181</td>\n",
              "      <td>0.030498</td>\n",
              "      <td>-0.300821</td>\n",
              "      <td>0.188728</td>\n",
              "      <td>-0.014946</td>\n",
              "      <td>-0.022813</td>\n",
              "      <td>0.142978</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.105227</td>\n",
              "      <td>-0.367590</td>\n",
              "      <td>0.057834</td>\n",
              "      <td>-0.623360</td>\n",
              "      <td>0.127633</td>\n",
              "      <td>-0.038408</td>\n",
              "      <td>-0.425345</td>\n",
              "      <td>-0.320201</td>\n",
              "      <td>-0.604526</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.340051</td>\n",
              "      <td>-0.145041</td>\n",
              "      <td>-0.165572</td>\n",
              "      <td>-0.362329</td>\n",
              "      <td>-0.119050</td>\n",
              "      <td>-0.301679</td>\n",
              "      <td>0.071205</td>\n",
              "      <td>0.355422</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.126925</td>\n",
              "      <td>0.020166</td>\n",
              "      <td>0.100932</td>\n",
              "      <td>-0.464344</td>\n",
              "      <td>0.496763</td>\n",
              "      <td>-0.215234</td>\n",
              "      <td>-0.526151</td>\n",
              "      <td>0.088354</td>\n",
              "      <td>-0.222541</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.196931</td>\n",
              "      <td>-0.343176</td>\n",
              "      <td>-0.005231</td>\n",
              "      <td>-0.042328</td>\n",
              "      <td>-0.142382</td>\n",
              "      <td>-0.003090</td>\n",
              "      <td>-0.035455</td>\n",
              "      <td>0.143022</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.060498</td>\n",
              "      <td>0.123393</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>-0.197850</td>\n",
              "      <td>0.097257</td>\n",
              "      <td>-0.048006</td>\n",
              "      <td>-0.041843</td>\n",
              "      <td>-0.272861</td>\n",
              "      <td>-0.017689</td>\n",
              "      <td>...</td>\n",
              "      <td>0.123482</td>\n",
              "      <td>-0.000749</td>\n",
              "      <td>-0.020878</td>\n",
              "      <td>-0.352778</td>\n",
              "      <td>-0.044268</td>\n",
              "      <td>-0.035371</td>\n",
              "      <td>-0.078913</td>\n",
              "      <td>0.105660</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6231</th>\n",
              "      <td>6231</td>\n",
              "      <td>-0.077220</td>\n",
              "      <td>-0.161203</td>\n",
              "      <td>0.018463</td>\n",
              "      <td>-0.457005</td>\n",
              "      <td>0.416739</td>\n",
              "      <td>0.028342</td>\n",
              "      <td>-0.353683</td>\n",
              "      <td>0.014565</td>\n",
              "      <td>-0.536690</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.317391</td>\n",
              "      <td>-0.395045</td>\n",
              "      <td>0.061353</td>\n",
              "      <td>-0.082348</td>\n",
              "      <td>-0.025392</td>\n",
              "      <td>-0.158036</td>\n",
              "      <td>0.239290</td>\n",
              "      <td>0.021167</td>\n",
              "      <td>114</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6232</th>\n",
              "      <td>6232</td>\n",
              "      <td>-0.032591</td>\n",
              "      <td>0.205356</td>\n",
              "      <td>0.195381</td>\n",
              "      <td>-0.296000</td>\n",
              "      <td>0.302850</td>\n",
              "      <td>-0.017343</td>\n",
              "      <td>-0.317731</td>\n",
              "      <td>0.061563</td>\n",
              "      <td>-0.385725</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.159178</td>\n",
              "      <td>-0.255210</td>\n",
              "      <td>0.135381</td>\n",
              "      <td>-0.090296</td>\n",
              "      <td>-0.139390</td>\n",
              "      <td>0.081853</td>\n",
              "      <td>0.071966</td>\n",
              "      <td>0.129449</td>\n",
              "      <td>114</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6233</th>\n",
              "      <td>6233</td>\n",
              "      <td>-0.094378</td>\n",
              "      <td>0.350528</td>\n",
              "      <td>-0.063975</td>\n",
              "      <td>-0.493669</td>\n",
              "      <td>0.322647</td>\n",
              "      <td>-0.105747</td>\n",
              "      <td>-0.243063</td>\n",
              "      <td>0.020720</td>\n",
              "      <td>-0.429954</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.072447</td>\n",
              "      <td>-0.226918</td>\n",
              "      <td>0.047581</td>\n",
              "      <td>-0.024180</td>\n",
              "      <td>-0.108588</td>\n",
              "      <td>0.060664</td>\n",
              "      <td>0.068632</td>\n",
              "      <td>0.147306</td>\n",
              "      <td>114</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6234</th>\n",
              "      <td>6234</td>\n",
              "      <td>-0.057526</td>\n",
              "      <td>0.246342</td>\n",
              "      <td>-0.407510</td>\n",
              "      <td>-0.405858</td>\n",
              "      <td>0.120783</td>\n",
              "      <td>-0.312137</td>\n",
              "      <td>-0.258789</td>\n",
              "      <td>-0.029895</td>\n",
              "      <td>-0.563389</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075562</td>\n",
              "      <td>-0.109152</td>\n",
              "      <td>0.039109</td>\n",
              "      <td>-0.225467</td>\n",
              "      <td>-0.039532</td>\n",
              "      <td>0.263450</td>\n",
              "      <td>-0.150685</td>\n",
              "      <td>0.219159</td>\n",
              "      <td>114</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6235</th>\n",
              "      <td>6235</td>\n",
              "      <td>-0.028098</td>\n",
              "      <td>0.238066</td>\n",
              "      <td>-0.148074</td>\n",
              "      <td>-0.105361</td>\n",
              "      <td>0.205518</td>\n",
              "      <td>-0.250160</td>\n",
              "      <td>-0.338060</td>\n",
              "      <td>-0.161969</td>\n",
              "      <td>-0.428494</td>\n",
              "      <td>...</td>\n",
              "      <td>0.089525</td>\n",
              "      <td>-0.020102</td>\n",
              "      <td>-0.012357</td>\n",
              "      <td>-0.192801</td>\n",
              "      <td>0.043596</td>\n",
              "      <td>0.155213</td>\n",
              "      <td>0.013843</td>\n",
              "      <td>0.191052</td>\n",
              "      <td>114</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6236 rows × 103 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a37d47f8-6375-4de6-afd9-8ba2ab5188cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a37d47f8-6375-4de6-afd9-8ba2ab5188cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a37d47f8-6375-4de6-afd9-8ba2ab5188cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple one layer Linear model"
      ],
      "metadata": {
        "id": "oADPVD2W-IA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)  \n",
        "        \n",
        "        #with torch.no_grad():\n",
        "           # self.linear.weight.div_(torch.norm(self.linear.weight, dim=1, keepdim=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        #self.linear.weight = torch.nn.Parameter(self.linear.weight/torch.norm(self.linear.weight))\n",
        "        #self.linear.bias = torch.nn.Parameter(self.linear.bias/torch.norm(self.linear.bias))\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Mcyfwdsbe-DX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Loop"
      ],
      "metadata": {
        "id": "4vL7Rq_A-NKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import normalize\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.autograd import Variable\n",
        "\n",
        "input_dim = 100\n",
        "output_dim = 100\n",
        "\n",
        "model = LinearModel(input_dim, output_dim).cuda()\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "learning_rate = 1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2)\n",
        "scheduler = StepLR(optimizer, step_size=3000, gamma=0.9)\n",
        "\n",
        "\n",
        "epochs = 50000\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    # Convert numpy array to torch Variable\n",
        "    \n",
        "    inputs = ar.cuda()\n",
        "    labels = fa.cuda()\n",
        "\n",
        "    # Clear gradients w.r.t. parameters\n",
        "    optimizer.zero_grad() \n",
        "    model.double()\n",
        "\n",
        "    # Forward to get output\n",
        "    #outputs = torch.from_numpy(normalize(model(inputs).detach().numpy(), axis=1, norm='l2')) \n",
        "    #model.linear.weight = torch.nn.Parameter(normalize(model.linear.weight))\n",
        "    #model.linear.bias = torch.nn.Parameter(model.linear.bias/torch.norm(model.linear.bias))\n",
        "    #print(model.linear.weight)\n",
        "    #print(normalize(model.linear.weight))\n",
        "    outputs = model(inputs)\n",
        "    #break\n",
        "    #outputs = normalize(model(inputs))\n",
        "\n",
        "    #print(torch.norm(outputs))\n",
        "    #print(np.linalg.norm(outputs[0, :]))\n",
        "    #loss.requres_grad = True\n",
        "\n",
        "    #A = outputs[0, :].detach().numpy()\n",
        "    #B = labels[0, :].detach().numpy()\n",
        "    #print(\"epoche : \" + str(epoch) + \"     \" + str(abs(np.dot(A,B)/(norm(A)*norm(B)))))\n",
        "\n",
        "\n",
        "    # Calculate Loss\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Getting gradients w.r.t. parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    #model.linear.weight = torch.nn.Parameter(normalize(model.linear.weight))\n",
        "    #model.linear.bias = torch.nn.Parameter(model.linear.bias/torch.norm(model.linear.bias))\n",
        " \n",
        "    if epoch % 1000 ==0 :\n",
        "      print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "    \n",
        "    epoch += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y1lZqap4-En",
        "outputId": "22b2c0ed-10c0-48e6-f09b-e72c51f7cab6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss 0.017512896102450378\n",
            "epoch 1000, loss 0.005089529311951608\n",
            "epoch 2000, loss 0.004745139250117934\n",
            "epoch 3000, loss 0.004492095218820194\n",
            "epoch 4000, loss 0.004303643233320378\n",
            "epoch 5000, loss 0.004161548720518299\n",
            "epoch 6000, loss 0.004053192886481015\n",
            "epoch 7000, loss 0.003969713446667993\n",
            "epoch 8000, loss 0.0039047979608895314\n",
            "epoch 9000, loss 0.0038538898486982637\n",
            "epoch 10000, loss 0.0038136586335936955\n",
            "epoch 11000, loss 0.0037816415549483703\n",
            "epoch 12000, loss 0.003755997789065981\n",
            "epoch 13000, loss 0.0037353376520013145\n",
            "epoch 14000, loss 0.0037186023901144495\n",
            "epoch 15000, loss 0.0037049785442887406\n",
            "epoch 16000, loss 0.0036938362418253356\n",
            "epoch 17000, loss 0.0036846842496285866\n",
            "epoch 18000, loss 0.003677136904974696\n",
            "epoch 19000, loss 0.003670889555736944\n",
            "epoch 20000, loss 0.0036657001602769085\n",
            "epoch 21000, loss 0.0036613753894994714\n",
            "epoch 22000, loss 0.0036577600495928952\n",
            "epoch 23000, loss 0.00365472897490891\n",
            "epoch 24000, loss 0.003652180772938138\n",
            "epoch 25000, loss 0.0036500329683265783\n",
            "epoch 26000, loss 0.003648218211079423\n",
            "epoch 27000, loss 0.0036466812995418476\n",
            "epoch 28000, loss 0.003645376831035529\n",
            "epoch 29000, loss 0.0036442673388023426\n",
            "epoch 30000, loss 0.003643321807795617\n",
            "epoch 31000, loss 0.003642514487127796\n",
            "epoch 32000, loss 0.0036418239359499597\n",
            "epoch 33000, loss 0.00364123225386493\n",
            "epoch 34000, loss 0.0036407244578614017\n",
            "epoch 35000, loss 0.0036402879760746745\n",
            "epoch 36000, loss 0.0036399122350697978\n",
            "epoch 37000, loss 0.003639588322277093\n",
            "epoch 38000, loss 0.003639308709038348\n",
            "epoch 39000, loss 0.003639067022706052\n",
            "epoch 40000, loss 0.003638857858574341\n",
            "epoch 41000, loss 0.0036386766242571516\n",
            "epoch 42000, loss 0.003638519410579082\n",
            "epoch 43000, loss 0.003638382884193596\n",
            "epoch 44000, loss 0.003638264198057138\n",
            "epoch 45000, loss 0.0036381609166174123\n",
            "epoch 46000, loss 0.003638070953158459\n",
            "epoch 47000, loss 0.00363799251721485\n",
            "epoch 48000, loss 0.003637924070346014\n",
            "epoch 49000, loss 0.003637864288867861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/MyDrive/Sources/ArToFa.pt')"
      ],
      "metadata": {
        "id": "CRGDycab-8hp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ArToFa = torch.load( '/content/drive/MyDrive/Sources/ArToFa.pt').cuda()\n",
        "ArToEn = torch.load( '/content/drive/MyDrive/Sources/ArToEn.pt').cuda()\n",
        "FaToEn = torch.load( '/content/drive/MyDrive/Sources/FaToEn.pt').cuda()"
      ],
      "metadata": {
        "id": "3-v9n9-CBpOy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translate Aya"
      ],
      "metadata": {
        "id": "FsSGHp1WB7ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_lines(filename) :\n",
        "  with open('/content/drive/MyDrive/Sources/' + filename) as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "  sura, aya, text = [], [], []\n",
        "  for line in lines:\n",
        "      temp = line.split('|')\n",
        "      if len(temp)==3:\n",
        "        sura.append(int(temp[0]))\n",
        "        aya.append(int(temp[1]))\n",
        "        text.append(temp[2])\n",
        "  df = pd.DataFrame()\n",
        "  df['sura'] = sura\n",
        "  df['aya'] = aya\n",
        "  df['text'] = text\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "eoEiUow9DB2m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "def translate_aya(index_aya, model, src, dst) : \n",
        "\n",
        " # print(src[index_aya, :].shape)\n",
        " # print(dst.shape)\n",
        "\n",
        "  src = src.cpu()\n",
        "  dst = dst.cpu()\n",
        "  model.cpu()\n",
        "  A = normalize(model(src).detach().numpy(), axis=1, norm='l2')[index_aya, :]\n",
        "\n",
        "  #print(A.shape)\n",
        "  outs = []\n",
        "  for i in range(6236) : \n",
        "  \n",
        "    #A = model(src[index_aya, :]).detach().numpy()\n",
        "    B = dst[i, :]\n",
        "    outs.append(np.dot(A,B)/(norm(A)*norm(B)))\n",
        "\n",
        "  print(max(outs))\n",
        "  return outs.index(max(outs))"
      ],
      "metadata": {
        "id": "q1Vxrf3nDqlj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_quran = read_lines('en.ahmedali.txt')\n",
        "fa_quran = read_lines('fa.ansarian.txt')\n",
        "ar_quran = read_lines('ar.jalalayn.txt')\n",
        "\n",
        "fa_quran"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cILi00kwCNGa",
        "outputId": "2af09b5b-eaf3-4a10-ce43-2b0c9b630458"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      sura  aya                                               text\n",
              "0        1    1  به نام خدا که رحمتش بی‌اندازه است و مهربانی‌اش...\n",
              "1        1    2  همه ستایش ها، ویژه خدا، مالک و مربّی جهانیان ا...\n",
              "2        1    3         رحمتش بی اندازه و مهربانی اش همیشگی است.\\n\n",
              "3        1    4           مالک و فرمانروای روز پاداش و کیفر است.\\n\n",
              "4        1    5  [پروردگارا!] تنها تو را می پرستیم وتنها از تو ...\n",
              "...    ...  ...                                                ...\n",
              "6231   114    2                                 [به] پادشاه مردم\\n\n",
              "6232   114    3                                  [به] معبود مردم\\n\n",
              "6233   114    4             از زیان وسوسه گر کمین گرفته و پنهان،\\n\n",
              "6234   114    5        آنکه همواره در سینه های مردم وسوسه می کند\\n\n",
              "6235   114    6                              از جنّیان و آدمیان.\\n\n",
              "\n",
              "[6236 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f78685b-17b4-4593-8338-d85c72ad8d78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sura</th>\n",
              "      <th>aya</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>به نام خدا که رحمتش بی‌اندازه است و مهربانی‌اش...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>همه ستایش ها، ویژه خدا، مالک و مربّی جهانیان ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>رحمتش بی اندازه و مهربانی اش همیشگی است.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>مالک و فرمانروای روز پاداش و کیفر است.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>[پروردگارا!] تنها تو را می پرستیم وتنها از تو ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6231</th>\n",
              "      <td>114</td>\n",
              "      <td>2</td>\n",
              "      <td>[به] پادشاه مردم\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6232</th>\n",
              "      <td>114</td>\n",
              "      <td>3</td>\n",
              "      <td>[به] معبود مردم\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6233</th>\n",
              "      <td>114</td>\n",
              "      <td>4</td>\n",
              "      <td>از زیان وسوسه گر کمین گرفته و پنهان،\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6234</th>\n",
              "      <td>114</td>\n",
              "      <td>5</td>\n",
              "      <td>آنکه همواره در سینه های مردم وسوسه می کند\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6235</th>\n",
              "      <td>114</td>\n",
              "      <td>6</td>\n",
              "      <td>از جنّیان و آدمیان.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6236 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f78685b-17b4-4593-8338-d85c72ad8d78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f78685b-17b4-4593-8338-d85c72ad8d78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f78685b-17b4-4593-8338-d85c72ad8d78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexToTranslate = 1000\n",
        "\n",
        "translated_index = translate_aya(indexToTranslate, FaToEn, fa, en)\n",
        "\n",
        "print(fa_quran.iloc[indexToTranslate, :])\n",
        "\n",
        "print(en_quran.iloc[translated_index, :])\n",
        "#translated = en_quran[translate_aya(6231, FaToEn, fa, en), :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3CqfI-QEpcY",
        "outputId": "c7c966c1-bafd-46a2-d646-439ae32c3f7a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9383789749361351\n",
            "sura                                                    7\n",
            "aya                                                    47\n",
            "text    و چون بهشتیان، چشمانشان ناخواسته به سوی دوزخیا...\n",
            "Name: 1000, dtype: object\n",
            "sura                                                    9\n",
            "aya                                                    74\n",
            "text    They swear by God: \"We never said this.\" But t...\n",
            "Name: 1308, dtype: object\n"
          ]
        }
      ]
    }
  ]
}
